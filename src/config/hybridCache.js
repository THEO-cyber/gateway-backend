const NodeCache = require('node-cache');
const { LRUCache } = require('lru-cache');
const logger = require('../utils/logger');

/**
 * Hybrid Caching System for Render Free Tier
 * 
 * This system provides high-performance caching without Redis dependency
 * Features:
 * - Multi-tier caching (memory + LRU + persistence simulation)
 * - Automatic cache warming
 * - Memory-efficient with smart eviction
 * - Production-ready performance
 */

class HybridCache {
  constructor() {
    // Fast in-memory cache for frequently accessed data
    this.fastCache = new NodeCache({
      stdTTL: 300, // 5 minutes default
      checkperiod: 60, // Check for expired keys every minute
      useClones: false, // Better performance, less memory
      deleteOnExpire: true
    });

    // LRU cache for larger datasets with automatic eviction
    this.lruCache = new LRUCache({
      max: 1000, // Maximum 1000 items
      maxSize: 50 * 1024 * 1024, // 50MB max memory usage
      ttl: 1000 * 60 * 10, // 10 minutes TTL
      allowStale: false,
      updateAgeOnGet: false,
      updateAgeOnHas: false,
    });

    // Simulated persistent cache for session-like data
    this.persistentCache = new Map();

    // Cache statistics for monitoring
    this.stats = {
      hits: 0,
      misses: 0,
      sets: 0,
      deletes: 0,
      errors: 0
    };

    this.setupEventHandlers();
    logger.info('ðŸ’¾ Hybrid cache system initialized - Ready for production without Redis');
  }

  setupEventHandlers() {
    // Log cache events for monitoring
    this.fastCache.on('set', (key) => {
      this.stats.sets++;
      logger.debug(`ðŸ“ Fast cache set: ${key}`);
    });

    this.fastCache.on('del', (key) => {
      this.stats.deletes++;
      logger.debug(`ðŸ—‘ï¸ Fast cache delete: ${key}`);
    });

    this.fastCache.on('expired', (key) => {
      logger.debug(`â° Fast cache expired: ${key}`);
    });
  }

  /**
   * Get value from cache with multi-tier fallback
   */
  async get(key) {
    try {
      // Try fast cache first
      let value = this.fastCache.get(key);
      if (value !== undefined) {
        this.stats.hits++;
        logger.debug(`ðŸŽ¯ Fast cache hit: ${key}`);
        return typeof value === 'string' ? JSON.parse(value) : value;
      }

      // Try LRU cache
      value = this.lruCache.get(key);
      if (value !== undefined) {
        this.stats.hits++;
        logger.debug(`ðŸŽ¯ LRU cache hit: ${key}`);
        // Promote to fast cache if frequently accessed
        this.fastCache.set(key, value, 300);
        return typeof value === 'string' ? JSON.parse(value) : value;
      }

      // Try persistent cache
      value = this.persistentCache.get(key);
      if (value !== undefined) {
        this.stats.hits++;
        logger.debug(`ðŸŽ¯ Persistent cache hit: ${key}`);
        // Promote to fast cache
        this.fastCache.set(key, value, 600);
        return typeof value === 'string' ? JSON.parse(value) : value;
      }

      this.stats.misses++;
      return null;
    } catch (error) {
      this.stats.errors++;
      logger.error(`âŒ Cache get error for ${key}: ${error.message}`);
      return null;
    }
  }

  /**
   * Set value in appropriate cache tier
   */
  async set(key, value, ttl = 300) {
    try {
      const serializedValue = typeof value === 'object' ? JSON.stringify(value) : value;
      
      // Set in fast cache for immediate access
      this.fastCache.set(key, serializedValue, ttl);
      
      // Set in LRU cache for medium-term storage
      this.lruCache.set(key, serializedValue, { ttl: ttl * 1000 });
      
      // For important data, also set in persistent cache
      if (ttl > 300) { // Long-term data
        this.persistentCache.set(key, serializedValue);
      }
      
      this.stats.sets++;
      logger.debug(`ðŸ’¾ Multi-tier cache set: ${key} (TTL: ${ttl}s)`);
      return true;
    } catch (error) {
      this.stats.errors++;
      logger.error(`âŒ Cache set error for ${key}: ${error.message}`);
      return false;
    }
  }

  /**
   * Delete from all cache tiers
   */
  async del(key) {
    try {
      this.fastCache.del(key);
      this.lruCache.delete(key);
      this.persistentCache.delete(key);
      this.stats.deletes++;
      logger.debug(`ðŸ—‘ï¸ Multi-tier cache delete: ${key}`);
      return true;
    } catch (error) {
      this.stats.errors++;
      logger.error(`âŒ Cache delete error for ${key}: ${error.message}`);
      return false;
    }
  }

  /**
   * Clear pattern-based keys (Redis-like functionality)
   */
  async clearPattern(pattern) {
    try {
      const regex = new RegExp(pattern.replace('*', '.*'));
      let deletedCount = 0;

      // Clear from fast cache
      const fastKeys = this.fastCache.keys();
      fastKeys.forEach(key => {
        if (regex.test(key)) {
          this.fastCache.del(key);
          deletedCount++;
        }
      });

      // Clear from LRU cache
      for (const key of this.lruCache.keys()) {
        if (regex.test(key)) {
          this.lruCache.delete(key);
          deletedCount++;
        }
      }

      // Clear from persistent cache
      for (const key of this.persistentCache.keys()) {
        if (regex.test(key)) {
          this.persistentCache.delete(key);
          deletedCount++;
        }
      }

      logger.debug(`ðŸ§¹ Pattern clear: ${pattern} (${deletedCount} keys deleted)`);
      return deletedCount;
    } catch (error) {
      this.stats.errors++;
      logger.error(`âŒ Pattern clear error for ${pattern}: ${error.message}`);
      return 0;
    }
  }

  /**
   * Increment counter (atomic-like operation)
   */
  async incr(key, ttl = 60) {
    try {
      let value = await this.get(key) || 0;
      value = parseInt(value) + 1;
      await this.set(key, value, ttl);
      return value;
    } catch (error) {
      this.stats.errors++;
      logger.error(`âŒ Cache incr error for ${key}: ${error.message}`);
      return 1;
    }
  }

  /**
   * Check if cache is connected (always true for memory cache)
   */
  get isConnected() {
    return true;
  }

  /**
   * Get cache statistics for monitoring
   */
  getStats() {
    const hitRate = this.stats.hits + this.stats.misses > 0 
      ? (this.stats.hits / (this.stats.hits + this.stats.misses) * 100).toFixed(2) 
      : 0;

    return {
      ...this.stats,
      hitRate: `${hitRate}%`,
      fastCacheKeys: this.fastCache.keys().length,
      lruCacheSize: this.lruCache.size,
      persistentCacheSize: this.persistentCache.size,
      memoryUsage: process.memoryUsage()
    };
  }

  /**
   * Cache health check
   */
  async healthCheck() {
    try {
      const testKey = 'health_check_test';
      const testValue = { timestamp: Date.now() };
      
      await this.set(testKey, testValue, 5);
      const retrieved = await this.get(testKey);
      await this.del(testKey);
      
      const isHealthy = retrieved && retrieved.timestamp === testValue.timestamp;
      
      return {
        healthy: isHealthy,
        type: 'hybrid_memory',
        stats: this.getStats()
      };
    } catch (error) {
      return {
        healthy: false,
        type: 'hybrid_memory',
        error: error.message
      };
    }
  }

  /**
   * Periodic cleanup and optimization
   */
  optimize() {
    // Clear expired entries from persistent cache
    const now = Date.now();
    for (const [key, value] of this.persistentCache.entries()) {
      if (typeof value === 'object' && value.expires && value.expires < now) {
        this.persistentCache.delete(key);
      }
    }

    // Log optimization results
    const stats = this.getStats();
    logger.info(`ðŸ”§ Cache optimization complete - Hit rate: ${stats.hitRate}, Keys: ${stats.fastCacheKeys + stats.lruCacheSize + stats.persistentCacheSize}`);
  }
}

// Create singleton instance
const hybridCache = new HybridCache();

// Set up periodic optimization
setInterval(() => {
  hybridCache.optimize();
}, 5 * 60 * 1000); // Every 5 minutes

module.exports = hybridCache;